{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOPS1AiNvVcDts73DPMq8Fv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h120750572/Auto-Deep-Research/blob/main/EBM_write_report_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython python-docx reportlab\n",
        "\n",
        "from Bio import Entrez\n",
        "from docx import Document\n",
        "\n",
        "# ‚úÖ PubMed API Ë®≠ÂÆö\n",
        "Entrez.email = \"lee.youngchang@gmail.com\"\n",
        "Entrez.api_key = \"6b6183ed0ec2f5b77583277dd4f56070b508\"\n",
        "\n",
        "# -------- Step 1. Query -------- #\n",
        "def generate_pico_queries(patient, intervention, comparison, outcomes):\n",
        "    if isinstance(outcomes, list):\n",
        "        outcome_str_pubmed = \" OR \".join([f'\"{o}\"' for o in outcomes])\n",
        "    else:\n",
        "        outcome_str_pubmed = f'\"{outcomes}\"'\n",
        "    return (\n",
        "        f'(\"{patient}\" AND \"{intervention}\" AND \"{comparison}\" AND ({outcome_str_pubmed})) '\n",
        "        f'AND (RCT OR \"randomized controlled trial\" OR review OR cohort) '\n",
        "        f'AND (\"2020\"[Date - Publication] : \"3000\"[Date - Publication])'\n",
        "    )\n",
        "\n",
        "# -------- Step 2. PubMed Fetch -------- #\n",
        "def fetch_pubmed_articles(query, max_results=15):\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results, sort=\"relevance\")\n",
        "    record = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    pmids = record[\"IdList\"]\n",
        "\n",
        "    results = []\n",
        "    if pmids:\n",
        "        handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(pmids), rettype=\"medline\", retmode=\"xml\")\n",
        "        papers = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        for paper in papers[\"PubmedArticle\"]:\n",
        "            try:\n",
        "                title = paper[\"MedlineCitation\"][\"Article\"][\"ArticleTitle\"]\n",
        "                authors = paper[\"MedlineCitation\"][\"Article\"][\"AuthorList\"]\n",
        "                author_str = \", \".join(\n",
        "                    [f\"{a['LastName']} {a.get('Initials','')}\" for a in authors if \"LastName\" in a]\n",
        "                )\n",
        "                journal = paper[\"MedlineCitation\"][\"Article\"][\"Journal\"][\"Title\"]\n",
        "                year = paper[\"MedlineCitation\"][\"Article\"][\"Journal\"][\"JournalIssue\"][\"PubDate\"].get(\"Year\", \"n.d.\")\n",
        "                abstract = paper[\"MedlineCitation\"][\"Article\"].get(\"Abstract\", {}).get(\"AbstractText\", [\"\"])[0]\n",
        "                doi = None\n",
        "                for id in paper[\"PubmedData\"][\"ArticleIdList\"]:\n",
        "                    if id.attributes[\"IdType\"] == \"doi\":\n",
        "                        doi = str(id)\n",
        "                results.append({\n",
        "                    \"title\": title,\n",
        "                    \"authors\": author_str,\n",
        "                    \"journal\": journal,\n",
        "                    \"year\": year,\n",
        "                    \"doi\": doi,\n",
        "                    \"pmid\": paper[\"MedlineCitation\"][\"PMID\"],\n",
        "                    \"abstract\": abstract\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(\"Error parsing paper:\", e)\n",
        "    return results\n",
        "\n",
        "# -------- Step 3. Critical Appraisal -------- #\n",
        "def auto_jadad_score(abstract):\n",
        "    score = 0\n",
        "    text = abstract.lower()\n",
        "    if \"randomized\" in text: score += 1\n",
        "    if \"computer\" in text or \"random number\" in text or \"table\" in text: score += 1\n",
        "    if \"double blind\" in text or \"placebo\" in text: score += 1\n",
        "    if \"identical\" in text or \"matching placebo\" in text: score += 1\n",
        "    if \"withdrawal\" in text or \"lost to follow\" in text or \"dropout\" in text: score += 1\n",
        "    return min(score, 5)\n",
        "\n",
        "def auto_nos_score(abstract):\n",
        "    score = {\"Selection\": 0, \"Comparability\": 0, \"Outcome\": 0}\n",
        "    text = abstract.lower()\n",
        "    if \"cohort\" in text or \"prospective\" in text or \"retrospective\" in text: score[\"Selection\"] = 1\n",
        "    if \"matched\" in text or \"adjusted\" in text or \"controlled\" in text: score[\"Comparability\"] = 1\n",
        "    if \"follow-up\" in text or \"mortality\" in text or \"pregnancy rate\" in text or \"outcome\" in text: score[\"Outcome\"] = 1\n",
        "    return score, sum(score.values())\n",
        "\n",
        "def auto_grade(abstract):\n",
        "    text = abstract.lower()\n",
        "    if \"randomized\" in text: return \"High\"\n",
        "    elif \"cohort\" in text: return \"Moderate\"\n",
        "    else: return \"Low\"\n",
        "\n",
        "def auto_appraise(articles):\n",
        "    appraisal = []\n",
        "    for i, art in enumerate(articles, 1):\n",
        "        abs_text = art['abstract'] if art['abstract'] else \"\"\n",
        "        if \"randomized\" in abs_text.lower():\n",
        "            appraisal.append({\n",
        "                \"id\": i, \"title\": art['title'], \"type\": \"RCT\",\n",
        "                \"Jadad\": auto_jadad_score(abs_text),\n",
        "                \"GRADE\": auto_grade(abs_text)\n",
        "            })\n",
        "        elif \"cohort\" in abs_text.lower():\n",
        "            nos_detail, nos_total = auto_nos_score(abs_text)\n",
        "            appraisal.append({\n",
        "                \"id\": i, \"title\": art['title'], \"type\": \"Cohort\",\n",
        "                \"NOS\": nos_detail, \"NOS_Total\": nos_total,\n",
        "                \"GRADE\": auto_grade(abs_text)\n",
        "            })\n",
        "        else:\n",
        "            appraisal.append({\n",
        "                \"id\": i, \"title\": art['title'], \"type\": \"Other\",\n",
        "                \"GRADE\": auto_grade(abs_text)\n",
        "            })\n",
        "    return appraisal\n",
        "\n",
        "# -------- Step 4. One-click Report Generator -------- #\n",
        "def generate_ebm_report(patient, intervention, comparison, outcomes, max_results=10, filename=\"EBM_Report.docx\"):\n",
        "    query = generate_pico_queries(patient, intervention, comparison, outcomes)\n",
        "    print(\"üîç PubMed Êü•Ë©¢Âºè:\\n\", query, \"\\n\")\n",
        "\n",
        "    articles = fetch_pubmed_articles(query, max_results=max_results)\n",
        "    appraisal = auto_appraise(articles)\n",
        "\n",
        "    doc = Document()\n",
        "    doc.add_heading(\"EBM Clinical Research Report\", 0)\n",
        "\n",
        "    # Title (PICO Summary)\n",
        "    doc.add_heading(\"PICO Question\", level=1)\n",
        "    doc.add_paragraph(f\"Patient: {patient}\")\n",
        "    doc.add_paragraph(f\"Intervention: {intervention}\")\n",
        "    doc.add_paragraph(f\"Comparison: {comparison}\")\n",
        "    doc.add_paragraph(f\"Outcome: {', '.join(outcomes)}\")\n",
        "\n",
        "    # Literature Search\n",
        "    doc.add_heading(\"Literature Search\", level=1)\n",
        "    for i, art in enumerate(articles, 1):\n",
        "        doc.add_paragraph(f\"[{i}] {art['title']} ({art['journal']}, {art['year']})\")\n",
        "        doc.add_paragraph(f\"Authors: {art['authors']}\")\n",
        "        doc.add_paragraph(f\"Abstract: {art['abstract']}\")\n",
        "        doc.add_paragraph(f\"PMID: {art['pmid']} | DOI: {art['doi']}\\n\")\n",
        "\n",
        "    # Critical Appraisal\n",
        "    doc.add_heading(\"Critical Appraisal\", level=1)\n",
        "    for a in appraisal:\n",
        "        if a[\"type\"] == \"RCT\":\n",
        "            doc.add_paragraph(f\"[{a['id']}] {a['title']} ‚Üí RCT\")\n",
        "            doc.add_paragraph(f\"  Jadad Score: {a['Jadad']}/5\")\n",
        "            doc.add_paragraph(f\"  GRADE: {a['GRADE']}\\n\")\n",
        "        elif a[\"type\"] == \"Cohort\":\n",
        "            doc.add_paragraph(f\"[{a['id']}] {a['title']} ‚Üí Cohort\")\n",
        "            doc.add_paragraph(f\"  NOS: {a['NOS']} (Total {a['NOS_Total']}/9)\")\n",
        "            doc.add_paragraph(f\"  GRADE: {a['GRADE']}\\n\")\n",
        "        else:\n",
        "            doc.add_paragraph(f\"[{a['id']}] {a['title']} ‚Üí Other\")\n",
        "            doc.add_paragraph(f\"  GRADE: {a['GRADE']}\\n\")\n",
        "\n",
        "    # Application Section\n",
        "    doc.add_heading(\"Application\", level=1)\n",
        "    doc.add_paragraph(\"Ê≠§ÈÉ®ÂàÜÂèØÁî±Á†îÁ©∂ËÄÖË£úÂÖÖÔºåÂåÖÊã¨Ôºö\")\n",
        "    doc.add_paragraph(\"- Ëá®Â∫äÈÅ©Áî®ÊÄßÔºàÁâπÂÆöÁóÖ‰∫∫Áæ§È´îÔºâ\")\n",
        "    doc.add_paragraph(\"- ÊàêÊú¨ÊïàÁõä\")\n",
        "    doc.add_paragraph(\"- Â∞çÈÜ´ÁôÇÂìÅË≥™ËàáÊ±∫Á≠ñÁöÑÂΩ±Èüø\")\n",
        "\n",
        "    # References\n",
        "    doc.add_heading(\"References (Vancouver)\", level=1)\n",
        "    for i, art in enumerate(articles, 1):\n",
        "        ref = f\"{i}. {art['authors']}. {art['title']}. {art['journal']}. {art['year']}; PMID:{art['pmid']}\"\n",
        "        if art[\"doi\"]: ref += f\". doi:{art['doi']}\"\n",
        "        doc.add_paragraph(ref)\n",
        "\n",
        "    doc.save(filename)\n",
        "    print(f\"üìÑ Â∑≤Ëº∏Âá∫Â†±ÂëäÔºö{filename}\")\n",
        "    return {\"Articles\": articles, \"Appraisal\": appraisal}\n"
      ],
      "metadata": {
        "id": "gcXPb_U7n3hH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}